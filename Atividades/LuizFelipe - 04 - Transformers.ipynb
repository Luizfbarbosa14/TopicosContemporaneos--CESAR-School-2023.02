{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"KwPrkUrDMIkr"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import math"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pos7QWJBMIk3"},"outputs":[],"source":["d_model = 512\n","num_heads = 8\n","d_ff = 2048\n","batch_size = 32"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"anFmVxCDMIk5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724891399668,"user_tz":180,"elapsed":9,"user":{"displayName":"LUIZ FELIPE MENEZES BARBOSA","userId":"06614666295474233696"}},"outputId":"bdf52670-75fd-4bc5-8f4f-69e06820ab65"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([50, 32, 512])\n"]}],"source":["class PositionalEncoding(nn.Module):\n","    def __init__(self, d_model, max_len=5000):\n","        super().__init__()\n","        pe = torch.zeros(max_len, d_model)\n","        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","        pe = pe.unsqueeze(0).transpose(0, 1)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","        return x + self.pe[:x.size(0), :]\n","\n","# Exemplo\n","max_len = 100\n","pos_encoding = PositionalEncoding(d_model, max_len)\n","\n","# (sequence_length, batch_size, d_model)\n","input_tensor = torch.randn(50, batch_size, d_model)\n","output_tensor = pos_encoding(input_tensor)\n","\n","print(output_tensor.shape)  # Output shape: (sequence_length, batch_size, d_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ty7_xX4tMIk8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724891399669,"user_tz":180,"elapsed":8,"user":{"displayName":"LUIZ FELIPE MENEZES BARBOSA","userId":"06614666295474233696"}},"outputId":"d44e12b1-ba18-447c-bbd7-8b05dfada318"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 50, 512])\n"]}],"source":["class MultiHeadAttention(nn.Module):\n","    def __init__(self, d_model, num_heads):\n","        super().__init__()\n","        # Verifica se o número de dimensões do modelo é divisível pelo número de cabeças\n","        assert d_model % num_heads == 0\n","\n","        # Número de dimensões por cabeça\n","        self.d_k = d_model // num_heads\n","        self.num_heads = num_heads\n","\n","        # Inicializa as camadas lineares para Q, K e V\n","        self.W_q = nn.Linear(d_model, d_model)\n","        self.W_k = nn.Linear(d_model, d_model)\n","        self.W_v = nn.Linear(d_model, d_model)\n","        self.W_o = nn.Linear(d_model, d_model)\n","\n","    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n","        # Calcula os scores fazendo o produto escalar entre Q e K e dividindo pela raiz quadrada de d_k\n","        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n","\n","        # Se a máscara for fornecida, aplica a máscara para os scores\n","        if mask is not None:\n","            scores = scores.masked_fill(mask == 0, float('-inf'))\n","\n","        # Calcula a softmax nos scores\n","        attention = torch.softmax(scores, dim=-1)\n","\n","        # Multiplica a matriz de atenção pelo valor V\n","        output = torch.matmul(attention, V)\n","        return output\n","\n","    def split_heads(self, x):\n","        # Divide a última dimensão em (num_heads, d_k)\n","        N, seq_len, d_model = x.size()\n","        return x.view(N, seq_len, self.num_heads, self.d_k).transpose(1, 2)\n","\n","    def combine_heads(self, x):\n","        # Inverte a operação de split_heads\n","        N, _, seq_len, _ = x.size()\n","        return x.transpose(1, 2).contiguous().view(N, seq_len, self.num_heads * self.d_k)\n","\n","    def forward(self, query, key, value, mask=None):\n","        N = query.shape[0]\n","        query_len, key_len, value_len = query.shape[1], key.shape[1], value.shape[1]\n","\n","        # Passa os valores de Q, K e V pela camada linear\n","        Q = self.split_heads(self.W_q(query))\n","        K = self.split_heads(self.W_k(key))\n","        V = self.split_heads(self.W_v(value))\n","\n","        # Calcula a atenção\n","        attention = self.scaled_dot_product_attention(Q, K, V, mask)\n","\n","        # Combina as cabeças e aplica a camada linear final\n","        output = self.combine_heads(attention)\n","        output = self.W_o(output)\n","        return output\n","\n","\n","multi_head_attn = MultiHeadAttention(d_model, num_heads)\n","\n","# (batch_size, sequence_length, d_model)\n","#query = torch.randn(batch_size, 50, d_model)\n","#key = torch.randn(batch_size, 50, d_model)\n","#value = torch.randn(batch_size, 50, d_model)\n","\n","x = torch.randn(batch_size, 50, d_model)\n","\n","output = multi_head_attn(x, x, x)\n","\n","print(output.shape)  # Output shape: (batch_size, sequence_length, d_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ArJ3_TkJMIk-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724891400166,"user_tz":180,"elapsed":502,"user":{"displayName":"LUIZ FELIPE MENEZES BARBOSA","userId":"06614666295474233696"}},"outputId":"d27b975b-a14d-42a8-ff0b-a382561b76a2"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 50, 512])\n"]}],"source":["class FeedForward(nn.Module):\n","    def __init__(self, d_model, d_ff):\n","        super().__init__()\n","        self.fc1 = nn.Linear(d_model, d_ff)\n","        self.fc2 = nn.Linear(d_ff, d_model)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        return self.fc2(self.relu(self.fc1(x)))\n","\n","\n","d_model = 512\n","d_ff = 2048\n","ffn = FeedForward(d_model, d_ff)\n","\n","# (batch_size, sequence_length, d_model)\n","input_tensor = torch.randn(32, 50, d_model)\n","\n","output = ffn(input_tensor)\n","\n","print(output.shape)  # Output shape: (batch_size, sequence_length, d_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SV1hObLdMIk_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724891400166,"user_tz":180,"elapsed":7,"user":{"displayName":"LUIZ FELIPE MENEZES BARBOSA","userId":"06614666295474233696"}},"outputId":"3b5963da-5739-453f-b0fc-9a18e07edcda"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 50, 512])\n"]}],"source":["class EncoderLayer(nn.Module):\n","    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n","        super().__init__()\n","        self.attention = MultiHeadAttention(d_model, num_heads)\n","        self.norm1 = nn.LayerNorm(d_model)\n","        self.ffn = FeedForward(d_model, d_ff)\n","        self.norm2 = nn.LayerNorm(d_model)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x, mask=None):\n","        attn_output = self.attention(x, x, x, mask)\n","        x = self.norm1(x + self.dropout(attn_output))\n","        ffn_output = self.ffn(x)\n","        x = self.norm2(x + self.dropout(ffn_output))\n","        return x\n","\n","\n","encoder_layer = EncoderLayer(d_model, num_heads, d_ff)\n","\n","# (batch_size, sequence_length, d_model)\n","input_tensor = torch.randn(32, 50, d_model)\n","\n","output = encoder_layer(input_tensor)\n","\n","print(output.shape)  # Output shape: (batch_size, sequence_length, d_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7W0xCtBKMIlC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724891405790,"user_tz":180,"elapsed":5628,"user":{"displayName":"LUIZ FELIPE MENEZES BARBOSA","userId":"06614666295474233696"}},"outputId":"0f1c9cc1-6de1-4b1d-c52e-4076433c25d2"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 100, 512])\n"]}],"source":["class Encoder(nn.Module):\n","    def __init__(self, src_vocab_size, d_model, num_heads, num_layers, d_ff, max_len, dropout=0.1):\n","        super().__init__()\n","        self.embedding = nn.Embedding(src_vocab_size, d_model)\n","        self.positional_encoding = PositionalEncoding(d_model, max_len)\n","        self.layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x, mask=None):\n","        # Embedding + positional encoding + dropout\n","        x = self.embedding(x)\n","        x = self.positional_encoding(x)\n","\n","        # Passa a entrada por cada camada do encoder\n","        for layer in self.layers:\n","            x = layer(x, mask)\n","\n","        return x\n","\n","\n","src_vocab_size = 1000\n","num_layers = 6\n","max_len = 100\n","\n","encoder = Encoder(src_vocab_size, d_model, num_heads, num_layers, d_ff, max_len)\n","\n","# (batch_size, sequence_length)\n","input_seq = torch.randint(0, src_vocab_size, (32, 100))\n","\n","output = encoder(input_seq)\n","\n","print(output.shape)  # Output shape: (batch_size, sequence_length, d_model)"]},{"cell_type":"code","source":["input_seq"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p3YIwptjP8l1","executionInfo":{"status":"ok","timestamp":1724891405791,"user_tz":180,"elapsed":14,"user":{"displayName":"LUIZ FELIPE MENEZES BARBOSA","userId":"06614666295474233696"}},"outputId":"724f9468-97d5-40d4-a125-7c60fc09c135"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[652, 770, 404,  ..., 360, 928, 717],\n","        [104, 920, 824,  ..., 381, 462, 580],\n","        [495, 618,  78,  ..., 937, 284, 376],\n","        ...,\n","        [962,  76, 566,  ..., 736, 243, 605],\n","        [103, 418, 226,  ..., 543, 468, 828],\n","        [116, 626, 739,  ..., 293, 603, 597]])"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W_CQgRErMIlE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724891405791,"user_tz":180,"elapsed":11,"user":{"displayName":"LUIZ FELIPE MENEZES BARBOSA","userId":"06614666295474233696"}},"outputId":"e03461b5-2104-4f74-b201-b9c11afe6d17"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 50, 512])\n"]}],"source":["class DecoderLayer(nn.Module):\n","    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n","        super().__init__()\n","        self.self_attention = MultiHeadAttention(d_model, num_heads)\n","        self.norm1 = nn.LayerNorm(d_model)\n","        self.cross_attention = MultiHeadAttention(d_model, num_heads)\n","        self.norm2 = nn.LayerNorm(d_model)\n","        self.ffn = FeedForward(d_model, d_ff)\n","        self.norm3 = nn.LayerNorm(d_model)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x, enc_out, src_mask=None, trg_mask=None):\n","        # Self-attention na sequência de destino\n","        self_attn_output = self.self_attention(x, x, x, trg_mask)\n","        x = self.norm1(x + self.dropout(self_attn_output))\n","\n","        # Cross-attention entre a saída do self-attention e a saída do encoder\n","        cross_attn_output = self.cross_attention(x, enc_out, enc_out, src_mask)\n","        x = self.norm2(x + self.dropout(cross_attn_output))\n","\n","        # Feed-forward\n","        ffn_output = self.ffn(x)\n","        x = self.norm3(x + self.dropout(ffn_output))\n","\n","        return x\n","\n","\n","decoder_layer = DecoderLayer(d_model, num_heads, d_ff)\n","\n","# (batch_size, sequence_length, d_model)\n","input_tensor = torch.randn(32, 50, d_model)\n","enc_out = torch.randn(32, 50, d_model)\n","\n","output = decoder_layer(input_tensor, enc_out)\n","\n","print(output.shape)  # Output shape: (batch_size, sequence_length, d_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jysAluZrMIlG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724891409609,"user_tz":180,"elapsed":3825,"user":{"displayName":"LUIZ FELIPE MENEZES BARBOSA","userId":"06614666295474233696"}},"outputId":"9b38e888-48a9-42d4-e432-d55691c9840e"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 100, 1000])\n"]}],"source":["# Decoder\n","class Decoder(nn.Module):\n","    def __init__(self, trg_vocab_size, d_model, num_heads, num_layers, d_ff, max_len, dropout=0.1):\n","        super(Decoder, self).__init__()\n","        self.embedding = nn.Embedding(trg_vocab_size, d_model)\n","        self.positional_encoding = PositionalEncoding(d_model, max_len)\n","        self.layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n","        self.fc_out = nn.Linear(d_model, trg_vocab_size)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x, enc_out, src_mask=None, trg_mask=None):\n","        # Embedding + positional encoding + dropout\n","        x = self.embedding(x)\n","        x = self.positional_encoding(x)\n","        x = self.dropout(x)\n","\n","        # Passa a entrada por cada camada do decoder\n","        for layer in self.layers:\n","            x = layer(x, enc_out, src_mask, trg_mask)\n","\n","        out = self.fc_out(x)\n","        return out\n","\n","\n","trg_vocab_size = 1000\n","num_layers = 6\n","max_len = 100\n","\n","decoder = Decoder(trg_vocab_size, d_model, num_heads, num_layers, d_ff, max_len)\n","\n","# (batch_size, sequence_length)\n","trg_seq = torch.randint(0, trg_vocab_size, (32, 100))\n","enc_out = torch.randn(32, 100, d_model)\n","\n","output = decoder(trg_seq, enc_out)\n","\n","print(output.shape)  # Output shape: (batch_size, sequence_length, trg_vocab_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BgWu3xV7MIlI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724891417606,"user_tz":180,"elapsed":8002,"user":{"displayName":"LUIZ FELIPE MENEZES BARBOSA","userId":"06614666295474233696"}},"outputId":"f5b478ea-4b3f-4b16-9ce8-33ff5dd20a0c"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 100, 1000])\n"]}],"source":["# Transformer Completo\n","class Transformer(nn.Module):\n","    def __init__(self, src_vocab_size, trg_vocab_size, d_model, num_heads, num_encoder_layers, num_decoder_layers, d_ff, max_len, dropout=0.1):\n","        super().__init__()\n","        self.encoder = Encoder(src_vocab_size, d_model, num_heads, num_encoder_layers, d_ff, max_len, dropout)\n","        self.decoder = Decoder(trg_vocab_size, d_model, num_heads, num_decoder_layers, d_ff, max_len, dropout)\n","\n","    def generate_mask(self, src, trg):\n","        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n","        trg_mask = (trg != 0).unsqueeze(1).unsqueeze(3)\n","        seq_length = trg.size(1)\n","        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool()\n","        trg_mask = trg_mask & nopeak_mask\n","        return src_mask, trg_mask\n","\n","    def forward(self, src, trg, src_mask=None, trg_mask=None):\n","        src_mask, trg_mask = self.generate_mask(src, trg)\n","        enc_out = self.encoder(src, src_mask)\n","        out = self.decoder(trg, enc_out, src_mask, trg_mask)\n","        return out\n","\n","\n","src_vocab_size = 1000\n","trg_vocab_size = 1000\n","d_model = 512\n","num_heads = 8\n","num_encoder_layers = 6\n","num_decoder_layers = 6\n","d_ff = 2048\n","max_len = 100\n","\n","transformer = Transformer(src_vocab_size, trg_vocab_size, d_model, num_heads, num_encoder_layers, num_decoder_layers, d_ff, max_len)\n","\n","# (batch_size, sequence_length)\n","src_seq = torch.randint(0, src_vocab_size, (batch_size, 100))\n","trg_seq = torch.randint(0, trg_vocab_size, (batch_size, 100))\n","\n","output = transformer(src_seq, trg_seq)\n","\n","print(output.shape)  # Output shape: (batch_size, target_sequence_length, trg_vocab_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q6s31Jj8MIlJ"},"outputs":[],"source":["# Gerando as máscaras de forma separada\n","\n","def create_padding_mask(seq):\n","    return (seq != 0).unsqueeze(1).unsqueeze(2).type(torch.uint8)  # Cria uma máscara para posições de preenchimento\n","\n","def create_look_ahead_mask(size):\n","    mask = (1 - torch.triu(torch.ones(size, size), diagonal=1)).type(torch.uint8)\n","    return mask  # Cria uma máscara triangular para impedir a atenção em tokens futuros"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZVnvfWpvMIlK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724891417607,"user_tz":180,"elapsed":17,"user":{"displayName":"LUIZ FELIPE MENEZES BARBOSA","userId":"06614666295474233696"}},"outputId":"cf69811f-1a1e-413c-8183-d3b76cb24a2c"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[[1, 1, 0, 1, 0]]]], dtype=torch.uint8)\n"]}],"source":["seq = torch.tensor([[1, 2, 0, 4, 0]])\n","padding_mask = create_padding_mask(seq)\n","print(padding_mask)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1HaPePJCMIlL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724891417607,"user_tz":180,"elapsed":16,"user":{"displayName":"LUIZ FELIPE MENEZES BARBOSA","userId":"06614666295474233696"}},"outputId":"f5d870c0-05b4-48a2-dfbc-295b9b789d88"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[1, 0, 0, 0, 0],\n","        [1, 1, 0, 0, 0],\n","        [1, 1, 1, 0, 0],\n","        [1, 1, 1, 1, 0],\n","        [1, 1, 1, 1, 1]], dtype=torch.uint8)\n"]}],"source":["look_ahead_mask = create_look_ahead_mask(5)\n","print(look_ahead_mask)"]},{"cell_type":"markdown","metadata":{"id":"FNb44jtzMIlM"},"source":["## Exercícios"]},{"cell_type":"markdown","metadata":{"id":"zg9C1MkDMIlQ"},"source":["### Exercício 1\n","Implemente um módulo que utilize apenas o módulo Encoder para a classificação de texto em `num_classes` classes. Para a obtenção do vetor de embedding de toda a sequência que será enviado para a cabeça de classificação, faça um pooling de média através da dimensão de sequência."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3f_8u_ZyMIlR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724891419982,"user_tz":180,"elapsed":2387,"user":{"displayName":"LUIZ FELIPE MENEZES BARBOSA","userId":"06614666295474233696"}},"outputId":"c5a0e15c-37c6-4e25-d844-42da65d1172b"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 5])\n"]}],"source":["class TextClassifier(nn.Module):\n","    def __init__(self, src_vocab_size, d_model, num_heads, num_layers, d_ff, max_len, num_classes, dropout=0.1):\n","        super().__init__()\n","        self.embedding = nn.Embedding(src_vocab_size, d_model)\n","        self.positional_encoding = PositionalEncoding(d_model, max_len)\n","        self.layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n","        self.fc = nn.Linear(d_model, num_classes)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x, mask=None):\n","        # Embedding + positional encoding + dropout\n","        x = self.embedding(x)\n","        x = self.positional_encoding(x)\n","        x = self.dropout(x)\n","\n","        # Passa a entrada por cada camada do encoder\n","        for layer in self.layers:\n","            x = layer(x, mask)\n","\n","        # Pooling de média\n","        x = x.mean(dim=1)\n","\n","        # Classificação\n","        out = self.fc(x)\n","\n","        return out\n","\n","src_vocab_size = 1000\n","num_layers = 6\n","max_len = 100\n","num_classes = 5\n","\n","encoder = TextClassifier(src_vocab_size, d_model, num_heads, num_layers, d_ff, max_len, num_classes)\n","\n","# (batch_size, sequence_length)\n","input_seq = torch.randint(0, src_vocab_size, (32, 100))\n","\n","output = encoder(input_seq)\n","\n","print(output.shape)  # Output shape: (batch_size, sequence_length, d_model)"]},{"cell_type":"markdown","metadata":{"id":"qmZNitTlMIlR"},"source":["### Exercício 2\n","Vamos implementar um modelo baseado em stack de decoders. Uma vez que não é necessário cross-attention, pois não há encoders, utilize o módulo `EncoderLayer`. O tamanho do vocabulário deverá ser de 50257, o tamanho dos embeddings de 768, 12 cabeças de atenção, 12 camadas, dimensão da camada feedforward de 3072 e tamanho máximo de sequência 1024. Em seguida, teste com valores aleatórios simulando uma sequência de tokens."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oP1-f-qSMIlS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724891887101,"user_tz":180,"elapsed":11460,"user":{"displayName":"LUIZ FELIPE MENEZES BARBOSA","userId":"06614666295474233696"}},"outputId":"306a6407-ed14-44ff-a24e-b55d01c87bd1"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([32, 50257])\n"]}],"source":["class TextGenerator(nn.Module):\n","    def __init__(self, src_vocab_size, d_model, num_heads, num_layers, d_ff, max_len, dropout=0.1):\n","        super().__init__()\n","        self.embedding = nn.Embedding(src_vocab_size, d_model)\n","        self.positional_encoding = PositionalEncoding(d_model, max_len)\n","        self.layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n","        self.fc = nn.Linear(d_model, src_vocab_size)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x, mask=None):\n","        # Embedding + positional encoding + dropout\n","        x = self.embedding(x)\n","        x = self.positional_encoding(x)\n","        x = self.dropout(x)\n","\n","        # Passa a entrada por cada camada do encoder\n","        for layer in self.layers:\n","            x = layer(x, mask)\n","\n","        # Pooling de média\n","        x = x.mean(dim=1)\n","\n","        # Classificação\n","        out = self.fc(x)\n","\n","        return out\n","\n","src_vocab_size = 50257\n","d_model = 768\n","num_heads = 12\n","num_layers = 12\n","max_len = 1024\n","d_ff = 3072\n","\n","generator = TextGenerator(src_vocab_size, d_model, num_heads, num_layers, d_ff, max_len)\n","\n","# (batch_size, sequence_length)\n","input_seq = torch.randint(0, src_vocab_size, (32, 100))\n","\n","output = generator(input_seq)\n","\n","print(output.shape)  # Output shape: (batch_size, sequence_length, d_model)"]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"colab":{"provenance":[{"file_id":"https://github.com/silvaan/topicos_contemporaneos/blob/main/Part%202%20-%20LLMs/03%20-%20Transformers.ipynb","timestamp":1723593899375}]}},"nbformat":4,"nbformat_minor":0}